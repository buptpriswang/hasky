{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".output_wrapper, .output {\n",
       "    height:auto !important;\n",
       "    max-height:10000px;  /* your desired max-height here */\n",
       "}\n",
       ".output_scroll {\n",
       "    box-shadow:none !important;\n",
       "    webkit-box-shadow:none !important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".output_wrapper, .output {\n",
    "    height:auto !important;\n",
    "    max-height:10000px;  /* your desired max-height here */\n",
    "}\n",
    ".output_scroll {\n",
    "    box-shadow:none !important;\n",
    "    webkit-box-shadow:none !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensorflow_version: 1.2.0-rc0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing vocabulary from file: /home/gezi/new/temp/image-caption/ai-challenger/tfrecord/seq-basic/vocab.txt\n",
      "INFO:tensorflow:Created vocabulary with 10148 words\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ENCODE_UNK 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_model will get feature_name Conv2d_7b_1x1\n",
      "image_feature: Tensor(\"Flatten/Reshape:0\", shape=(?, 98304), dtype=float32)\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "image_model will get feature_name Conv2d_7b_1x1\n",
      "image_feature: Tensor(\"Flatten_1/Reshape:0\", shape=(?, 98304), dtype=float32)\n",
      "INFO:tensorflow:Restoring parameters from /home/gezi/data/image_model_check_point/inception_resnet_v2_2016_08_30.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "restore image var from InceptionResnetV2 /home/gezi/data/image_model_check_point/inception_resnet_v2_2016_08_30.ckpt duration: 3.77244091034\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import matplotlib\n",
    "#matplotlib.use('agg')\n",
    "#import matplotlib.pyplot as plt \n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import skimage.transform\n",
    "from scipy import ndimage\n",
    "import scipy.misc\n",
    "\n",
    "def image_show(image_path):\n",
    "  imshow(np.asarray(Image.open(image_path, 'r')))\n",
    "  plt.show()\n",
    "\n",
    "import tensorflow as tf\n",
    "import sys, os, math\n",
    "import gezi, melt\n",
    "import numpy as np\n",
    "\n",
    "TEXT_MAX_WORDS = 100    \n",
    "decode_max_words = 20\n",
    "\n",
    "\n",
    "from deepiu.util import ids2text\n",
    "vocab_path = '/home/gezi/new/temp/image-caption/ai-challenger/tfrecord/seq-basic/vocab.txt'\n",
    "ids2text.init(vocab_path)\n",
    "\n",
    "image_dir = image_dir = '/home/gezi/data2/data/ai_challenger/image_caption/pic/'\n",
    "image_file = '6275b5349168ac3fab6a493c509301d023cf39d3.jpg'\n",
    "image_path = os.path.join(image_dir, image_file)\n",
    "image_model_checkpoint_path = '/home/gezi/data/image_model_check_point/inception_resnet_v2_2016_08_30.ckpt'\n",
    "image_model_name='InceptionResnetV2'\n",
    "model_dir = '/home/gezi/new/temp/image-caption/ai-challenger/model/showattentell.rnn2/'\n",
    "if not melt.varname_in_checkpoint(image_model_name, model_dir):\n",
    "  image_model = melt.image.ImageModel(image_model_checkpoint_path, \n",
    "                                      model_name=image_model_name,\n",
    "                                      feature_name=melt.image.get_features_name(image_model_name))\n",
    "else:\n",
    "  image_model = None\n",
    "\n",
    "predictor = melt.Predictor(model_dir)\n",
    "\n",
    "model_dir2 = '/home/gezi/new/temp/image-caption/ai-challenger/model/showattentell.rnn.finetune.later'\n",
    "#predictor2 = melt.Predictor(model_dir2)\n",
    "\n",
    "import libpinyin\n",
    "pinyin = libpinyin.Pinyin()\n",
    "pinyin.Load('./data/pinyin/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(image_path, predictor, length_normalization_factor=1., gen_feature=True, num_show=1):\n",
    "  img = melt.read_image(image_path)\n",
    "  if gen_feature:\n",
    "    feature = image_model.gen_feature(img) if image_model is not None else img\n",
    "  else:\n",
    "    feature = [img]\n",
    "  #print(feature)\n",
    "  timer = gezi.Timer()\n",
    "  graph = predictor.graph\n",
    "  init_states = predictor.inference([\n",
    "                                        'beam_search_beam_size',\n",
    "                                        'beam_search_initial_state', \n",
    "                                        'beam_search_initial_ids', \n",
    "                                        'beam_search_initial_logprobs',\n",
    "                                        'beam_search_initial_alignments'\n",
    "                                        ], \n",
    "                                        feed_dict= {\n",
    "                                          graph.get_collection('feed')[0] : feature\n",
    "                                        })\n",
    "\n",
    "  step_func = lambda input_feed, state_feed : predictor.inference([\n",
    "                                        'beam_search_state', \n",
    "                                        'beam_search_ids', \n",
    "                                        'beam_search_logprobs',\n",
    "                                        'beam_search_alignments', \n",
    "                                        ], \n",
    "                                        feed_dict= {\n",
    "                                          #TODO...attetion still need input_text feed, see rnn_decoder.py  beam_search_step\n",
    "                                          #but not hurt perfomance much because encoder is fast? Is it possible to avoid this?\n",
    "                                          #anyway if no attention  will not need input_text_feed\n",
    "                                          graph.get_collection('feed')[0] : feature,\n",
    "                                          graph.get_collection('beam_search_input_feed')[0] : input_feed,\n",
    "                                          graph.get_collection('beam_search_state_feed')[0] : state_feed\n",
    "                                        })\n",
    "\n",
    "  beams = melt.seq2seq.beam_search(init_states, \n",
    "                                   step_func, \n",
    "                                   end_id=ids2text.end_id(), \n",
    "                                   max_words=decode_max_words, \n",
    "                                   length_normalization_factor=length_normalization_factor)\n",
    "\n",
    "\n",
    "  for i, beam in enumerate(beams):\n",
    "    print(i, beam.words, ids2text.ids2text(beam.words), math.exp(beam.score))\n",
    "\n",
    "    # Plot images with attention weights\n",
    "    words = beam.words    \n",
    "    img = ndimage.imread(image_path)\n",
    "    \n",
    "    num_features = melt.image.get_num_features(image_model_name)\n",
    "    dim = int(np.sqrt(num_features))\n",
    "    #print('dim:', dim)\n",
    "\n",
    "    n_words = len(words)\n",
    "    n_words += 1 #for ori image\n",
    "    w = np.round(np.sqrt(n_words))\n",
    "    h = np.ceil(np.float32(n_words) / w)\n",
    "    \n",
    "    #print(n_words, w, h)\n",
    "            \n",
    "    plt.subplot(w, h, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    #img = scipy.misc.imresize(img, (dim, dim))  \n",
    "\n",
    "    #smooth = True  #TODO smooth = Ture seems not work not back ground pic\n",
    "    smooth = False\n",
    "    if i < 1:  \n",
    "      for j in range(len(words)):\n",
    "        plt.subplot(w, h, j + 2)\n",
    "        lab = pinyin.Convert(ids2text.vocab.key(words[j]).decode('utf8').encode('gbk'))\n",
    "        lab += '(%0.2f)'%math.exp(beam.logprobs[j])\n",
    "        plt.text(0, 1, lab, backgroundcolor='white', fontsize=10)\n",
    "        plt.text(0, 1, lab, color='black', fontsize=10)\n",
    "        plt.imshow(img)\n",
    "        if smooth:\n",
    "          alpha_img = skimage.transform.pyramid_expand(beam.alignments_list[j].reshape(dim, dim), upscale=16, sigma=20)\n",
    "        else:\n",
    "          alpha_img = skimage.transform.resize(beam.alignments_list[j].reshape(dim, dim), [img.shape[0], img.shape[1]])\n",
    "        plt.imshow(alpha_img, alpha=0.8)\n",
    "        plt.set_cmap(cm.Greys_r)\n",
    "        plt.axis('off')\n",
    "      plt.show()\n",
    "      #plt.savefig('test%d.pdf'%i)\n",
    "\n",
    "    #print('beam search using time(ms):', timer.elapsed_ms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "  image_name = raw_input('image_name like 6275b5349168ac3fab6a493c509301d023cf39d3.jpg:')\n",
    "  image_name = image_name.strip()\n",
    "  if image_name == 'q':\n",
    "    break\n",
    "  if not image_name.endswith('.jpg'):\n",
    "    image_name += '.jpg'\n",
    "  image_path = os.path.join(image_dir, image_name)\n",
    "  \n",
    "  if not os.path.exists(image_path):\n",
    "    print('path not exists:%s'%image_path)\n",
    "    continue\n",
    "    \n",
    "  image_show(image_path)\n",
    "  predict(image_path, predictor)\n",
    "  #predict(image_path, predictor2, gen_feature=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
