{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from IPython.display import Image\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "import skimage.transform\n",
    "from scipy import ndimage\n",
    "\n",
    "def image_show(image_path):\n",
    "  imshow(np.asarray(Image.open(image_path, 'r')))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEeCAYAAACpGzMjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x56d9bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas import DataFrame \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.font_manager import FontProperties \n",
    "\n",
    "font = FontProperties(fname=\"/home/gezi/soft/simsunttc/msyh.ttf\", size=12)  #size可不用指定\n",
    "#font = FontProperties(fname=\"/home/gezi/soft/simsunttc/simsun.ttc\", size=12)  #size可不用指定\n",
    "\n",
    "# linux 的中文字体 /usr/share/fonts/simhei/simhei.ttf\n",
    "\n",
    "df = DataFrame({\"score\":[80, 90]}, index=[\"张三\",\"李四\"]) \n",
    "ax = df.plot(kind = 'bar', rot = 0) \n",
    "labels = [label.decode(\"utf-8\") for label in df.index.values] \n",
    "ax.set_xticklabels(labels, fontproperties=font) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".output_wrapper, .output {\n",
       "    height:auto !important;\n",
       "    max-height:10000px;  /* your desired max-height here */\n",
       "}\n",
       ".output_scroll {\n",
       "    box-shadow:none !important;\n",
       "    webkit-box-shadow:none !important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".output_wrapper, .output {\n",
    "    height:auto !important;\n",
    "    max-height:10000px;  /* your desired max-height here */\n",
    "}\n",
    ".output_scroll {\n",
    "    box-shadow:none !important;\n",
    "    webkit-box-shadow:none !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensorflow_version: 1.2.0-rc0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, os, math\n",
    "import gezi, melt\n",
    "import numpy as np\n",
    "\n",
    "TEXT_MAX_WORDS = 100    \n",
    "decode_max_words = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import libpinyin\n",
    "pinyin = libpinyin.Pinyin()\n",
    "pinyin.Load('./data/pinyin/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing vocabulary from file: /home/gezi/new/temp/image-caption/ai-challenger/tfrecord/seq-basic/vocab.txt\n",
      "INFO:tensorflow:Created vocabulary with 10148 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ENCODE_UNK 1\n"
     ]
    }
   ],
   "source": [
    "from deepiu.util import ids2text\n",
    "vocab_path = '/home/gezi/new/temp/image-caption/ai-challenger/tfrecord/seq-basic/vocab.txt'\n",
    "ids2text.init(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from /home/gezi/data/image_model_check_point/inception_resnet_v2_2016_08_30.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "restore image var from InceptionResnetV2 /home/gezi/data/image_model_check_point/inception_resnet_v2_2016_08_30.ckpt duration: 2.98462104797\n"
     ]
    }
   ],
   "source": [
    "image_dir = image_dir = '/home/gezi/data2/data/ai_challenger/image_caption/pic/'\n",
    "image_file = '6275b5349168ac3fab6a493c509301d023cf39d3.jpg'\n",
    "image_path = os.path.join(image_dir, image_file)\n",
    "image_model_checkpoint_path = '/home/gezi/data/image_model_check_point/inception_resnet_v2_2016_08_30.ckpt'\n",
    "model_name='InceptionResnetV2'\n",
    "image_model = melt.image.ImageModel(image_model_checkpoint_path, \n",
    "                                    model_name=model_name,\n",
    "                                    feature_name=melt.image.get_features_name(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/gezi/new/temp/image-caption/ai-challenger/model/showattentell/model.ckpt-25.6-105000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "restore meta grpah and model ok /home/gezi/new/temp/image-caption/ai-challenger/model/showattentell/model.ckpt-25.6-105000 duration: 28.13646698\n"
     ]
    }
   ],
   "source": [
    "model_dir = '/home/gezi/new/temp/image-caption/ai-challenger/model/showattentell/'\n",
    "predictor = melt.Predictor(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(image_name, num_show=1):\n",
    "  image_path = image_path = os.path.join(image_dir, image_name)\n",
    "  feature = image_model.gen_feature(melt.read_image(image_path))\n",
    "  timer = gezi.Timer()\n",
    "  init_states = predictor.inference([\n",
    "                                        'beam_search_beam_size',\n",
    "                                        'beam_search_initial_state', \n",
    "                                        'beam_search_initial_ids', \n",
    "                                        'beam_search_initial_logprobs',\n",
    "                                        'beam_search_initial_alignments'\n",
    "                                        ], \n",
    "                                        feed_dict= {\n",
    "                                          tf.get_collection('feed')[0] : feature\n",
    "                                        })\n",
    "\n",
    "  step_func = lambda input_feed, state_feed : predictor.inference([\n",
    "                                        'beam_search_state', \n",
    "                                        'beam_search_ids', \n",
    "                                        'beam_search_logprobs',\n",
    "                                        'beam_search_alignments', \n",
    "                                        ], \n",
    "                                        feed_dict= {\n",
    "                                          #TODO...attetion still need input_text feed, see rnn_decoder.py  beam_search_step\n",
    "                                          #but not hurt perfomance much because encoder is fast? Is it possible to avoid this?\n",
    "                                          #anyway if no attention  will not need input_text_feed\n",
    "                                          tf.get_collection('feed')[0] : feature,\n",
    "                                          tf.get_collection('beam_search_input_feed')[0] : input_feed,\n",
    "                                          tf.get_collection('beam_search_state_feed')[0] : state_feed\n",
    "                                        })\n",
    "\n",
    "  beams = melt.seq2seq.beam_search(init_states, \n",
    "                                   step_func, \n",
    "                                   end_id=ids2text.end_id(), \n",
    "                                   max_words=decode_max_words, \n",
    "                                   length_normalization_factor=0.)\n",
    "\n",
    "\n",
    "  for i, beam in enumerate(beams):\n",
    "    if i == num_show:\n",
    "      break\n",
    "\n",
    "    print(i, beam.words, ids2text.ids2text(beam.words), math.exp(beam.logprob), beam.logprob, beam.score, beam.logprobs)\n",
    "\n",
    "    # Plot images with attention weights\n",
    "    words = beam.words    \n",
    "    img = ndimage.imread(image_path)\n",
    "    plt.clf()\n",
    "    plt.subplot(4, 5, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    num_features = melt.image.get_num_features(model_name)\n",
    "    dim = int(math.sqrt(num_features))\n",
    "    \n",
    "    for t in range(len(words)):\n",
    "      plt.subplot(4, 5, t + 2)\n",
    "      plt.text(0, 1, '%s(%.2f)' % (pinyin.Convert(ids2text.vocab.key(words[t]).decode('utf8').encode('gbk')), math.exp(beam.logprobs[t])), color='black', backgroundcolor='white',fontsize=8)  \n",
    "      plt.imshow(img)\n",
    "      alp_curr = beam.alignments_list[t].reshape([dim, dim])\n",
    "      alp_img = skimage.transform.pyramid_expand(alp_curr, upscale=16, sigma=20)\n",
    "      plt.imshow(alp_img, alpha=0.85)\n",
    "      plt.axis('off')\n",
    "    plt.savefig(str(i) + 'test.pdf')\n",
    "\n",
    "  print('beam search using time(ms):', timer.elapsed_ms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_name like 6275b5349168ac3fab6a493c509301d023cf39d3.jpg:a02e4a220b9973233d77d90658b74d52c10c0bd0.jpg\n",
      "0 [10, 20, 73, 1, 14, 2, 62, 5, 81, 9] 一个/穿着/运动服/的/男人/在/运动场/上/踢足球/</S> 0.0233810016887 -3.75583 -3.75583 [-0.60450196, -0.3111428, -1.3762783, -0.0057475776, -0.12090515, -0.014540776, -1.272158, -0.0049367677, -0.045234434, -0.00038580605]\n",
      "beam search using time(ms): 1317.75212288\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "  image_name = raw_input('image_name like 6275b5349168ac3fab6a493c509301d023cf39d3.jpg:')\n",
    "  if image_name == 'q':\n",
    "    break\n",
    "  if not image_name.endswith('.jpg'):\n",
    "    image_name += '.jpg'\n",
    "  predict(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_words = alpha.shape[0] + 1\n",
    "w = numpy.round(numpy.sqrt(n_words))\n",
    "h = numpy.ceil(numpy.float32(n_words) / w)\n",
    "        \n",
    "plt.subplot(w, h, 1)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "\n",
    "smooth = True\n",
    "\n",
    "for ii in xrange(alpha.shape[0]):\n",
    "    plt.subplot(w, h, ii+2)\n",
    "    lab = words[ii]\n",
    "    if options['selector']:\n",
    "        lab += '(%0.2f)'%sels[ii]\n",
    "    plt.text(0, 1, lab, backgroundcolor='white', fontsize=13)\n",
    "    plt.text(0, 1, lab, color='black', fontsize=13)\n",
    "    plt.imshow(img)\n",
    "    if smooth:\n",
    "        alpha_img = skimage.transform.pyramid_expand(alpha[ii,0,:].reshape(14,14), upscale=16, sigma=20)\n",
    "    else:\n",
    "        alpha_img = skimage.transform.resize(alpha[ii,0,:].reshape(14,14), [img.shape[0], img.shape[1]])\n",
    "    plt.imshow(alpha_img, alpha=0.8)\n",
    "    plt.set_cmap(cm.Greys_r)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
