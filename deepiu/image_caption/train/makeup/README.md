learning rate is important for finetune if settint learning rate 0.1 will train convergent   
but overfit for eval set from the start like train loss 0.07, eval loss 0.49, setting to 0.01 is ok   
now only tested adagrad  
